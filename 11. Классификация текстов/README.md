# 11. Классификация текстов

### Цели проекта

- Обучить модель классифицировать комментарии по эмоциональному окрасу (позитивные, негативные). В распоряжении набор данных с разметкой о токсичности сообщений.
- Построить модель со значением метрики качества F1 не меньше 0.75.

### Задачи проекта

- Загрузить и подготовить данные.
- Обучить разные модели.
- Сделать выводы.

### Итоги

В качестве исходных данных нам был предоставлен датасет и мы:
* Загрузили данные. Обработка не требуется. Требуется подготовка признаков для обучения моделей.
* Написали функции лемматизации и очистки текста
* Лемматизировали и очистили текст
* Написали функцию разделения данных c отображением дисбаланса меток 1 и 0
* Разделили данные на обучающую, валидационную и тестовую выборки
* Создадим три выборки: обучающую, валидационную и тестовую
* Напишем функцию "борьбы" с дисбалансом, воспользуемся техниками увеличение выборки (upsampling), уменьшение выборки(downsampling).

Далее:
* Были обучены четыре модели с подбором гиперпараметров.
* С задачей справилась только логистическая регрессия, F1-мера = 0.780
* Чуть хуже XGBoost F1-мера = 0.740 и дерево решений F1-мера = 0.700
* Случайный лес показал худшие результаты.

После борьбы с дисбалансом:
* Метод downsampling смог незначительно улучшить f1-меру до 0.783

Результаты выбора модели:
* Логистическая регрессия на тестовой выборке показала отличные значения: F1-мера = 0.780 | Метрика AUC-ROC = 0.968, accuracy = 0.959
* Можно сделать вывод что для текстов больше подходит модель логистической регрессии, если не считать модели типа bert.
* Задание выполнено F1-мера = 0.780 (больше 0.75)

Классификация на эмбеддингах на небольшой выборке (2000) показала:
* Были обучены четыре модели с подбором гиперпараметров.
* О результатах трудно судит на такой маленькой выборке, но уже видно, что логистическач регрессия на эмбедингах бердом близка к TF-IDF. Случайный лес стал лучше выглядеть. Думаю, результаты улучшатся если взять выборку в несколько раз больше.

Подытожить работу можно так:
* Выбрана модель логистическач регрессия с классификацией текста методом TF-IDF
* В зависимости от ситуации необходимо подбирать именно ту модель которая будет показывать оптимальные результаты и не обязательно использовать классификацию на эмбеддингах, полученных с помощью модели BERT. Как в данном случае.

### Используемый стек инструментов

- python
- pandas
- numpy
- sklearn
- nltk
- matplotlib
- seaborn
- stop-words
- pymystem3
- xgboost
- torch
- transformers
- tensorflow
- bert
- xgboost
