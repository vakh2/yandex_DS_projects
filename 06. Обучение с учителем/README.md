# 6. Обучение с учителем

### Цели проекта

- Проанализировать исторические данные о поведении клиентов банка, расторжении договоров. Спрогнозировать уход клиента из банка.
- Построить модель классификации, метрика качества f1 (минимальное значение 0.59)
- Измерить AUC-ROC, сравнить её значение с f1-мерой.

### Задачи проекта

- Загрузить и подготовить данные. Пояснить порядок действий.
- Исследовать баланс классов, обучить модель без учёта дисбаланса. Кратко описать выводы.
- Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую. Кратко описать выводы.
- Провести финальное тестирование.
- Сделать общий вывод

### Итоги

В ходе проекта:
* Изучили данные
* Удалили лишние столбцы, которые либо дублируют индексы, либо не являются признаками.
* Проверили на дубликаты
* Подготовили для исследования три датафрейма:
 * в первом удалили строки с NaN
 * во втором NaN заменили на ноль
 * в третьем NaN заменили на медианное значение
 
**Итого, у нас для рассмотрения три датафрейма df_without_nan, df_with_zero, df_with_median.**
**Без учета дисбаланса классов:**
 
* Изучили дисбаланс классов: Соотношение меток 1 и 0 в таргете: 3.9
* Учитывая соотношение меток 1 и 0 в таргете разбили каждый из подгоовленных датафреймов (df_without_nan, df_with_zero, df_with_median) на три выборки в соотношении 3:1:1
* Написали функцию построения ROC-кривой и нахождения метрики качества AUC-ROC и представления F1 меры
* Написали функцию, которая перебором, меняя параметры и гиперпараметры ищет лучшую модель по максимальной F1-мере
* С помощью функции обучили разные модели (DecisionTreeClassifier, RandomForestClassifier, LogisticRegression) без учета дисбаланса классов и выбрали лучшие из них.
1. Лучшие модели, обученные на df_without_nan:
 * Для дерева решений F1-мера = 0.551 | Mетрика AUC-ROC = 0.825, accuracy = 0.855
 * Для случайного леса F1-мера = 0.589 | Mетрика AUC-ROC = 0.840, accuracy = 0.868
 * Для логистической регрессии F1-мера = 0.337 | Mетрика AUC-ROC = 0.742, accuracy = 0.821
2. Лучшие модели, обученные на df_with_zero:
 * Для дерева решений F1-мера = 0.544 | Mетрика AUC-ROC = 0.806, accuracy = 0.851
 * Для случайного леса F1-мера = 0.559 | Mетрика AUC-ROC = 0.819, accuracy = 0.846
 * Для логистической регрессии F1-мера = 0.238 | Mетрика AUC-ROC = 0.738, accuracy = 0.805
3. Лучшие модели, обученные на df_with_median:
 * Для дерева решений F1-мера = 0.544 | Mетрика AUC-ROC = 0.806, accuracy = 0.851
 * Для случайного леса F1-мера = 0.567 | Mетрика AUC-ROC = 0.824, accuracy = 0.851
 * Для логистической регрессии F1-мера = 0.240 | Mетрика AUC-ROC = 0.734, accuracy = 0.806 

**Лучшей моделью c F1-мерой = 0.589  оказалась модель случайного леса обученая на данных с удаленными стоками NaN с параметрами:(RandomForestClassifier(bootstrap=False, min_weight_fraction_leaf=0.001,n_estimators=12, random_state=12345))**

**Значение F1-меры = 0.589 удовлетворяет заданию проекта, причем метрика AUC-ROC = 0.840, accuracy = 0.868 также является отличным результатом.**

**С учетом дисбаланса классов:**

* Для борьбы с дисбалансом воспользовались техниками: увеличение выборки (upsampling), уменьшение выборки(downsampling) и изменением class_weight
* Написали функцию, который перебором, меняя параметры и гиперпараметры а также меняя количество раз увеличения (уменьшения) положительных объектов и изменением class_weight ищет лучшую модель по максимальной F1-мере
* С помощью функции обучили разные модели (DecisionTreeClassifier, RandomForestClassifier, LogisticRegression) без учета дисбаланса классов и выбрали лучшие из них.
1. Лучшие модели, обученные на df_without_nan:
 * Для дерева решений F1-мера = 0.582 | Mетрика AUC-ROC = 0.829, accuracy = 0.819
 * Для случайного леса F1-мера = 0.614 | Mетрика AUC-ROC = 0.834, accuracy = 0.847
 * Для логистической регрессии F1-мера = 0.488 | Mетрика AUC-ROC = 0.760, accuracy = 0.696
2. Лучшие модели, обученные на df_with_zero:
 * Для дерева решений F1-мера = 0.544 | Mетрика AUC-ROC = 0.806, accuracy = 0.851
 * Для случайного леса F1-мера = 0.559 | Mетрика AUC-ROC = 0.819, accuracy = 0.846
 * Для логистической регрессии F1-мера = 0.238 | Mетрика AUC-ROC = 0.738, accuracy = 0.805
3. Лучшие модели, обученные на df_with_median:
 * Для дерева решений F1-мера = 0.544 | Mетрика AUC-ROC = 0.806, accuracy = 0.851
 * Для случайного леса F1-мера = 0.567 | Mетрика AUC-ROC = 0.824, accuracy = 0.851
 * Для логистической регрессии F1-мера = 0.240 | Mетрика AUC-ROC = 0.734, accuracy = 0.806

**Лучшей моделью c F1-мерой = 0.614 оказалась модель случайного леса обученая на данных с удаленными стоками NaN с параметрами:(RandomForestClassifier(class_weight={0: 0.25, 1: 1.0}, criterion='entropy',min_weight_fraction_leaf=0.001, n_estimators=22,
random_state=12345))**

**Значение F1-меры = 0.61 удовлетворяет заданию проекта, причем метрика AUC-ROC = 0.834, accuracy = 0.847 также является отличным результатом.**

**Финальное тестирование на тестовой выборке выбранной модели:**

* Лучшей модель :(RandomForestClassifier(class_weight={0: 0.25, 1: 1.0}, criterion='entropy',min_weight_fraction_leaf=0.001, n_estimators=22, random_state=12345))

показала отличные результаты: F1-мера = 0.630 | Mетрика AUC-ROC = 0.824, accuracy = 0.851

* Метрика F1 больше 0,59, что является фактом успешного результата по проекту


### Используемый стек инструментов

- python
- pandas
- numpy
- sklearn
- matplotlib
- seaborn
- warnings
- random